# 100 Days of GPU Challenge ðŸš€

Thanks to [Umar Jamil](https://github.com/hkproj/100-days-of-gpu) for organizing this challenge!

Welcome to my journey through the 100 Days of GPU Challenge! This repository documents my progress as I learn GPU programming from scratch, writing one CUDA kernel each day to explore different concepts and optimization techniques.

## Progress Log

Click on the links below to explore the details of each day's kernel to find a description of the kernel, the CUDA code, performance analysis, results for each day's learning, etc.

- [**Day 1: Introduction to CUDA & Basic GPU Queries**](./day01)
- [**Day 2: Vector Addition Acceleration**](./day02)
- [**Day 3: Matrix Multiplication Acceleration**](./day03)
- [**Day 4: CUDA Image Processing - RGB to Grayscale & Image Blurring**](./day04)
- [**Day 5: GPU Accelerated Array Summation**](./day05)
- [**Day 6: GPU Accelerated Matrix Multiplication with Tiling**](./day06)
- [**Day 7: GPU Accelerated Gaussian Blur with PyCUDA**](./day07)
- [**Day 8: GPU Accelerated 2D Convolution with He Normal Initialization**](./day08)
- [**Day 9: Laplacian Edge Detection with PyCUDA**](./day09)
- [**Day 10: Tiled 2D Convolution for Enhanced Performance**](./day10)
- [**Day 11: 3D Stencil Operation Acceleration**](./day11)
- [**Day 12: Optimized 3D Stencil Operation with Tiling**](./day12)
- [**Day 13: Thread Coarsening for 3D Stencil Operation**](./day13)
- [**Day 14: Histogram Calculation Optimization with Privatization and Shared Memory**](./day14)
- [**Day 15: Thread Coarsening Strategies for Histogram Optimization and Scalability**](./day15)
- [**Day 16: Revisiting Day 5 - Optimization with Shared Memory and Thread Coarsening, RTX A4000 Limit Testing**](./day16)
- [**Day 17: Kogge-Stone Prefix Sum Algorithm - Shared Memory and Double Buffering Optimizations**](./day17)
- [**Day 18: Brent-Kung Prefix Sum Algorithm - Exploring Trade-offs in Parallel Prefix Sum**](./day18)
- [**Day 19: GPU Accelerated Merge Operation - Hybrid CPU/GPU Approach**](./day19)
- [**Day 20: Tiled GPU Merge - Enhancing Performance with Shared Memory Tiling**](./day20)
- [**Day 21: Radix Sort - Bitwise Sorting with GPU Acceleration using Brent-Kung Scan**](./day21)
- [**Day 22: Radix Sort Optimization - Shared Memory for Enhanced Bitwise Sorting**](./day22)
- [**Day 23: Sparse Matrix Formats - COO and CSR for Efficient Storage**](./day23)
- [**Day 24: Sparse Matrix-Vector Multiplication (SpMV) - COO vs. CSR Performance on GPU**](./day24)
- [**Day 25: Data Type Performance - Benchmarking ReLU Activation with FP64, FP32, FP16, and INT8 on RTX A4000**](./day25)
- [**Day 26: Precision Analysis of Activation Functions - FP64, FP32, FP16, and INT8 Performance**](./day26)
- [**Day 27: Exploring ELL and JDS Sparse Matrix Formats**](./day27)
- [**Day 28: SpMV Performance with ELL Sparse Matrix Format**](./day28)
- [**Day 29: Completion of SpMV Implementations and Comparative Analysis (COO, CSR, ELL, JDS)**](./day29)
- [**Day 30: Achieving Peak 2D Convolution Performance: Custom CUDA Kernel vs. cuDNN**](./day30)
- [**Day 31: Implementing 2D Max Pooling in CUDA**](./day31)
- [**Day 32: Introduction to Triton: Vector Addition**](./day32)