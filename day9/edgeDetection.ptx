//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-33281558
// Cuda compilation tools, release 12.3, V12.3.52
// Based on NVVM 7.0.1
//

.version 8.3
.target sm_86
.address_size 64

	// .globl	RGB2Grayscale

.visible .entry RGB2Grayscale(
	.param .u64 RGB2Grayscale_param_0,
	.param .u64 RGB2Grayscale_param_1,
	.param .u32 RGB2Grayscale_param_2,
	.param .u32 RGB2Grayscale_param_3
)
{
	.reg .pred 	%p<10>;
	.reg .b16 	%rs<22>;
	.reg .f32 	%f<43>;
	.reg .b32 	%r<59>;
	.reg .b64 	%rd<33>;


	ld.param.u64 	%rd3, [RGB2Grayscale_param_0];
	ld.param.u64 	%rd4, [RGB2Grayscale_param_1];
	ld.param.u32 	%r19, [RGB2Grayscale_param_2];
	ld.param.u32 	%r20, [RGB2Grayscale_param_3];
	cvta.to.global.u64 	%rd1, %rd4;
	cvta.to.global.u64 	%rd2, %rd3;
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r21, %ctaid.x;
	mov.u32 	%r22, %tid.x;
	mad.lo.s32 	%r56, %r21, %r1, %r22;
	mov.u32 	%r23, %ntid.y;
	mov.u32 	%r24, %ctaid.y;
	mov.u32 	%r25, %tid.y;
	mad.lo.s32 	%r3, %r24, %r23, %r25;
	mov.u32 	%r26, %nctaid.y;
	mul.lo.s32 	%r4, %r26, %r23;
	setp.ge.s32 	%p1, %r56, %r19;
	setp.ge.s32 	%p2, %r3, %r20;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB0_9;

	add.s32 	%r27, %r4, %r20;
	add.s32 	%r5, %r3, %r4;
	not.b32 	%r28, %r5;
	add.s32 	%r29, %r27, %r28;
	div.u32 	%r6, %r29, %r4;
	add.s32 	%r30, %r6, 1;
	and.b32  	%r7, %r30, 3;
	mul.lo.s32 	%r8, %r3, %r19;
	mul.lo.s32 	%r9, %r5, %r19;
	add.s32 	%r10, %r5, %r4;
	mul.lo.s32 	%r11, %r10, %r19;
	add.s32 	%r12, %r10, %r4;
	mov.u32 	%r31, %nctaid.x;
	mul.lo.s32 	%r13, %r31, %r1;

$L__BB0_2:
	setp.eq.s32 	%p4, %r7, 0;
	mov.u32 	%r57, %r3;
	@%p4 bra 	$L__BB0_6;

	setp.eq.s32 	%p5, %r7, 1;
	add.s32 	%r32, %r8, %r56;
	mul.lo.s32 	%r33, %r32, 3;
	cvt.s64.s32 	%rd5, %r33;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.u8 	%rs1, [%rd6];
	cvt.rn.f32.u16 	%f1, %rs1;
	ld.global.u8 	%rs2, [%rd6+1];
	cvt.rn.f32.u16 	%f2, %rs2;
	mul.f32 	%f3, %f2, 0f3F35C28F;
	fma.rn.f32 	%f4, %f1, 0f3E570A3D, %f3;
	ld.global.u8 	%rs3, [%rd6+2];
	cvt.rn.f32.u16 	%f5, %rs3;
	fma.rn.f32 	%f6, %f5, 0f3D8F5C29, %f4;
	cvt.rzi.u32.f32 	%r34, %f6;
	cvt.s64.s32 	%rd7, %r32;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.u8 	[%rd8], %r34;
	mov.u32 	%r57, %r5;
	@%p5 bra 	$L__BB0_6;

	setp.eq.s32 	%p6, %r7, 2;
	add.s32 	%r35, %r9, %r56;
	mul.lo.s32 	%r36, %r35, 3;
	cvt.s64.s32 	%rd9, %r36;
	add.s64 	%rd10, %rd2, %rd9;
	ld.global.u8 	%rs4, [%rd10];
	cvt.rn.f32.u16 	%f7, %rs4;
	ld.global.u8 	%rs5, [%rd10+1];
	cvt.rn.f32.u16 	%f8, %rs5;
	mul.f32 	%f9, %f8, 0f3F35C28F;
	fma.rn.f32 	%f10, %f7, 0f3E570A3D, %f9;
	ld.global.u8 	%rs6, [%rd10+2];
	cvt.rn.f32.u16 	%f11, %rs6;
	fma.rn.f32 	%f12, %f11, 0f3D8F5C29, %f10;
	cvt.rzi.u32.f32 	%r37, %f12;
	cvt.s64.s32 	%rd11, %r35;
	add.s64 	%rd12, %rd1, %rd11;
	st.global.u8 	[%rd12], %r37;
	mov.u32 	%r57, %r10;
	@%p6 bra 	$L__BB0_6;

	add.s32 	%r38, %r11, %r56;
	mul.lo.s32 	%r39, %r38, 3;
	cvt.s64.s32 	%rd13, %r39;
	add.s64 	%rd14, %rd2, %rd13;
	ld.global.u8 	%rs7, [%rd14];
	cvt.rn.f32.u16 	%f13, %rs7;
	ld.global.u8 	%rs8, [%rd14+1];
	cvt.rn.f32.u16 	%f14, %rs8;
	mul.f32 	%f15, %f14, 0f3F35C28F;
	fma.rn.f32 	%f16, %f13, 0f3E570A3D, %f15;
	ld.global.u8 	%rs9, [%rd14+2];
	cvt.rn.f32.u16 	%f17, %rs9;
	fma.rn.f32 	%f18, %f17, 0f3D8F5C29, %f16;
	cvt.rzi.u32.f32 	%r40, %f18;
	cvt.s64.s32 	%rd15, %r38;
	add.s64 	%rd16, %rd1, %rd15;
	st.global.u8 	[%rd16], %r40;
	mov.u32 	%r57, %r12;

$L__BB0_6:
	setp.lt.u32 	%p7, %r6, 3;
	@%p7 bra 	$L__BB0_8;

$L__BB0_7:
	mad.lo.s32 	%r41, %r57, %r19, %r56;
	mul.lo.s32 	%r42, %r41, 3;
	cvt.s64.s32 	%rd17, %r42;
	add.s64 	%rd18, %rd2, %rd17;
	ld.global.u8 	%rs10, [%rd18];
	cvt.rn.f32.u16 	%f19, %rs10;
	ld.global.u8 	%rs11, [%rd18+1];
	cvt.rn.f32.u16 	%f20, %rs11;
	mul.f32 	%f21, %f20, 0f3F35C28F;
	fma.rn.f32 	%f22, %f19, 0f3E570A3D, %f21;
	ld.global.u8 	%rs12, [%rd18+2];
	cvt.rn.f32.u16 	%f23, %rs12;
	fma.rn.f32 	%f24, %f23, 0f3D8F5C29, %f22;
	cvt.rzi.u32.f32 	%r43, %f24;
	cvt.s64.s32 	%rd19, %r41;
	add.s64 	%rd20, %rd1, %rd19;
	st.global.u8 	[%rd20], %r43;
	add.s32 	%r44, %r57, %r4;
	mad.lo.s32 	%r45, %r44, %r19, %r56;
	mul.lo.s32 	%r46, %r45, 3;
	cvt.s64.s32 	%rd21, %r46;
	add.s64 	%rd22, %rd2, %rd21;
	ld.global.u8 	%rs13, [%rd22];
	cvt.rn.f32.u16 	%f25, %rs13;
	ld.global.u8 	%rs14, [%rd22+1];
	cvt.rn.f32.u16 	%f26, %rs14;
	mul.f32 	%f27, %f26, 0f3F35C28F;
	fma.rn.f32 	%f28, %f25, 0f3E570A3D, %f27;
	ld.global.u8 	%rs15, [%rd22+2];
	cvt.rn.f32.u16 	%f29, %rs15;
	fma.rn.f32 	%f30, %f29, 0f3D8F5C29, %f28;
	cvt.rzi.u32.f32 	%r47, %f30;
	cvt.s64.s32 	%rd23, %r45;
	add.s64 	%rd24, %rd1, %rd23;
	st.global.u8 	[%rd24], %r47;
	add.s32 	%r48, %r44, %r4;
	mad.lo.s32 	%r49, %r48, %r19, %r56;
	mul.lo.s32 	%r50, %r49, 3;
	cvt.s64.s32 	%rd25, %r50;
	add.s64 	%rd26, %rd2, %rd25;
	ld.global.u8 	%rs16, [%rd26];
	cvt.rn.f32.u16 	%f31, %rs16;
	ld.global.u8 	%rs17, [%rd26+1];
	cvt.rn.f32.u16 	%f32, %rs17;
	mul.f32 	%f33, %f32, 0f3F35C28F;
	fma.rn.f32 	%f34, %f31, 0f3E570A3D, %f33;
	ld.global.u8 	%rs18, [%rd26+2];
	cvt.rn.f32.u16 	%f35, %rs18;
	fma.rn.f32 	%f36, %f35, 0f3D8F5C29, %f34;
	cvt.rzi.u32.f32 	%r51, %f36;
	cvt.s64.s32 	%rd27, %r49;
	add.s64 	%rd28, %rd1, %rd27;
	st.global.u8 	[%rd28], %r51;
	add.s32 	%r52, %r48, %r4;
	mad.lo.s32 	%r53, %r52, %r19, %r56;
	mul.lo.s32 	%r54, %r53, 3;
	cvt.s64.s32 	%rd29, %r54;
	add.s64 	%rd30, %rd2, %rd29;
	ld.global.u8 	%rs19, [%rd30];
	cvt.rn.f32.u16 	%f37, %rs19;
	ld.global.u8 	%rs20, [%rd30+1];
	cvt.rn.f32.u16 	%f38, %rs20;
	mul.f32 	%f39, %f38, 0f3F35C28F;
	fma.rn.f32 	%f40, %f37, 0f3E570A3D, %f39;
	ld.global.u8 	%rs21, [%rd30+2];
	cvt.rn.f32.u16 	%f41, %rs21;
	fma.rn.f32 	%f42, %f41, 0f3D8F5C29, %f40;
	cvt.rzi.u32.f32 	%r55, %f42;
	cvt.s64.s32 	%rd31, %r53;
	add.s64 	%rd32, %rd1, %rd31;
	st.global.u8 	[%rd32], %r55;
	add.s32 	%r57, %r52, %r4;
	setp.lt.s32 	%p8, %r57, %r20;
	@%p8 bra 	$L__BB0_7;

$L__BB0_8:
	add.s32 	%r56, %r56, %r13;
	setp.lt.s32 	%p9, %r56, %r19;
	@%p9 bra 	$L__BB0_2;

$L__BB0_9:
	ret;

}
	// .globl	intToFloat
.visible .entry intToFloat(
	.param .u64 intToFloat_param_0,
	.param .u64 intToFloat_param_1,
	.param .u32 intToFloat_param_2,
	.param .u32 intToFloat_param_3
)
{
	.reg .pred 	%p<4>;
	.reg .b16 	%rs<2>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<12>;
	.reg .b64 	%rd<9>;


	ld.param.u64 	%rd1, [intToFloat_param_0];
	ld.param.u64 	%rd2, [intToFloat_param_1];
	ld.param.u32 	%r3, [intToFloat_param_2];
	ld.param.u32 	%r4, [intToFloat_param_3];
	mov.u32 	%r5, %ctaid.x;
	mov.u32 	%r6, %ntid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r1, %r5, %r6, %r7;
	mov.u32 	%r8, %ntid.y;
	mov.u32 	%r9, %ctaid.y;
	mov.u32 	%r10, %tid.y;
	mad.lo.s32 	%r2, %r9, %r8, %r10;
	setp.ge.s32 	%p1, %r1, %r3;
	setp.ge.s32 	%p2, %r2, %r4;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB1_2;

	cvta.to.global.u64 	%rd3, %rd1;
	mad.lo.s32 	%r11, %r2, %r3, %r1;
	cvt.s64.s32 	%rd4, %r11;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.u8 	%rs1, [%rd5];
	cvt.rn.f32.u16 	%f1, %rs1;
	cvta.to.global.u64 	%rd6, %rd2;
	mul.wide.s32 	%rd7, %r11, 4;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f32 	[%rd8], %f1;

$L__BB1_2:
	ret;

}
	// .globl	imageBlur
.visible .entry imageBlur(
	.param .u64 imageBlur_param_0,
	.param .u64 imageBlur_param_1,
	.param .u32 imageBlur_param_2,
	.param .u32 imageBlur_param_3
)
{
	.reg .pred 	%p<41>;
	.reg .b32 	%r<118>;
	.reg .b64 	%rd<9>;


	ld.param.u64 	%rd4, [imageBlur_param_0];
	ld.param.u64 	%rd5, [imageBlur_param_1];
	ld.param.u32 	%r65, [imageBlur_param_2];
	ld.param.u32 	%r66, [imageBlur_param_3];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r67, %ctaid.x;
	mul.lo.s32 	%r2, %r67, %r1;
	mov.u32 	%r3, %tid.x;
	add.s32 	%r97, %r2, %r3;
	mov.u32 	%r5, %ntid.y;
	mov.u32 	%r68, %ctaid.y;
	mul.lo.s32 	%r6, %r68, %r5;
	mov.u32 	%r7, %tid.y;
	add.s32 	%r8, %r6, %r7;
	setp.ge.s32 	%p1, %r97, %r65;
	@%p1 bra 	$L__BB2_22;

	mov.u32 	%r70, %nctaid.x;
	mov.u32 	%r71, %nctaid.y;
	add.s32 	%r72, %r3, %r2;
	add.s32 	%r73, %r7, %r6;
	add.s32 	%r74, %r73, -3;
	mad.lo.s32 	%r9, %r65, %r74, %r72;
	mul.lo.s32 	%r13, %r1, %r70;
	mul.lo.s32 	%r12, %r5, %r71;
	mul.lo.s32 	%r11, %r12, %r65;
	cvta.to.global.u64 	%rd1, %rd5;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r96, 0;

$L__BB2_2:
	setp.ge.s32 	%p2, %r8, %r66;
	@%p2 bra 	$L__BB2_21;

	add.s32 	%r16, %r97, -3;
	add.s32 	%r17, %r97, -2;
	add.s32 	%r18, %r97, -1;
	add.s32 	%r19, %r97, 1;
	add.s32 	%r20, %r97, 2;
	add.s32 	%r21, %r97, 3;
	mad.lo.s32 	%r22, %r13, %r96, %r9;
	mov.u32 	%r75, 0;
	mov.u32 	%r98, %r75;
	mov.u32 	%r99, %r8;

$L__BB2_4:
	mad.lo.s32 	%r25, %r11, %r98, %r22;
	add.s32 	%r101, %r99, -3;
	mov.u32 	%r100, %r75;
	mov.u32 	%r105, %r75;
	mov.u32 	%r104, %r75;

$L__BB2_5:
	mad.lo.s32 	%r79, %r65, %r100, %r25;
	cvt.s64.s32 	%rd6, %r79;
	add.s64 	%rd3, %rd2, %rd6;
	or.b32  	%r80, %r16, %r101;
	setp.lt.s32 	%p3, %r80, 0;
	setp.ge.s32 	%p4, %r101, %r66;
	or.pred  	%p5, %p4, %p3;
	setp.ge.s32 	%p6, %r16, %r65;
	or.pred  	%p7, %p6, %p5;
	@%p7 bra 	$L__BB2_7;

	ld.global.u8 	%r81, [%rd3+-3];
	add.s32 	%r104, %r104, %r81;
	add.s32 	%r105, %r105, 1;

$L__BB2_7:
	or.b32  	%r82, %r17, %r101;
	setp.lt.s32 	%p8, %r82, 0;
	or.pred  	%p10, %p4, %p8;
	setp.ge.s32 	%p11, %r17, %r65;
	or.pred  	%p12, %p11, %p10;
	@%p12 bra 	$L__BB2_9;

	ld.global.u8 	%r83, [%rd3+-2];
	add.s32 	%r104, %r104, %r83;
	add.s32 	%r105, %r105, 1;

$L__BB2_9:
	or.b32  	%r84, %r18, %r101;
	setp.lt.s32 	%p13, %r84, 0;
	or.pred  	%p15, %p4, %p13;
	setp.gt.s32 	%p16, %r97, %r65;
	or.pred  	%p17, %p16, %p15;
	@%p17 bra 	$L__BB2_11;

	ld.global.u8 	%r85, [%rd3+-1];
	add.s32 	%r104, %r104, %r85;
	add.s32 	%r105, %r105, 1;

$L__BB2_11:
	or.b32  	%r86, %r97, %r101;
	setp.lt.s32 	%p18, %r86, 0;
	or.pred  	%p20, %p4, %p18;
	setp.ge.s32 	%p21, %r97, %r65;
	or.pred  	%p22, %p21, %p20;
	@%p22 bra 	$L__BB2_13;

	ld.global.u8 	%r87, [%rd3];
	add.s32 	%r104, %r104, %r87;
	add.s32 	%r105, %r105, 1;

$L__BB2_13:
	or.b32  	%r88, %r19, %r101;
	setp.lt.s32 	%p23, %r88, 0;
	or.pred  	%p25, %p4, %p23;
	setp.ge.s32 	%p26, %r19, %r65;
	or.pred  	%p27, %p26, %p25;
	@%p27 bra 	$L__BB2_15;

	ld.global.u8 	%r89, [%rd3+1];
	add.s32 	%r104, %r104, %r89;
	add.s32 	%r105, %r105, 1;

$L__BB2_15:
	or.b32  	%r90, %r20, %r101;
	setp.lt.s32 	%p28, %r90, 0;
	or.pred  	%p30, %p4, %p28;
	setp.ge.s32 	%p31, %r20, %r65;
	or.pred  	%p32, %p31, %p30;
	@%p32 bra 	$L__BB2_17;

	ld.global.u8 	%r91, [%rd3+2];
	add.s32 	%r104, %r104, %r91;
	add.s32 	%r105, %r105, 1;

$L__BB2_17:
	or.b32  	%r92, %r21, %r101;
	setp.lt.s32 	%p33, %r92, 0;
	or.pred  	%p35, %p4, %p33;
	setp.ge.s32 	%p36, %r21, %r65;
	or.pred  	%p37, %p36, %p35;
	@%p37 bra 	$L__BB2_19;

	ld.global.u8 	%r93, [%rd3+3];
	add.s32 	%r104, %r104, %r93;
	add.s32 	%r105, %r105, 1;

$L__BB2_19:
	add.s32 	%r101, %r101, 1;
	setp.ne.s32 	%p38, %r100, 6;
	add.s32 	%r100, %r100, 1;
	@%p38 bra 	$L__BB2_5;

	div.s32 	%r94, %r104, %r105;
	mad.lo.s32 	%r95, %r99, %r65, %r97;
	cvt.s64.s32 	%rd7, %r95;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.u8 	[%rd8], %r94;
	add.s32 	%r99, %r99, %r12;
	setp.lt.s32 	%p39, %r99, %r66;
	add.s32 	%r98, %r98, 1;
	@%p39 bra 	$L__BB2_4;

$L__BB2_21:
	add.s32 	%r97, %r97, %r13;
	setp.lt.s32 	%p40, %r97, %r65;
	add.s32 	%r96, %r96, 1;
	@%p40 bra 	$L__BB2_2;

$L__BB2_22:
	ret;

}
	// .globl	edgeDetectionLaplacianConv2D
.visible .entry edgeDetectionLaplacianConv2D(
	.param .u64 edgeDetectionLaplacianConv2D_param_0,
	.param .u64 edgeDetectionLaplacianConv2D_param_1,
	.param .u64 edgeDetectionLaplacianConv2D_param_2,
	.param .u32 edgeDetectionLaplacianConv2D_param_3,
	.param .u32 edgeDetectionLaplacianConv2D_param_4
)
{
	.reg .pred 	%p<37>;
	.reg .f32 	%f<47>;
	.reg .b32 	%r<30>;
	.reg .b64 	%rd<15>;


	ld.param.u64 	%rd7, [edgeDetectionLaplacianConv2D_param_0];
	ld.param.u64 	%rd6, [edgeDetectionLaplacianConv2D_param_1];
	ld.param.u64 	%rd8, [edgeDetectionLaplacianConv2D_param_2];
	ld.param.u32 	%r8, [edgeDetectionLaplacianConv2D_param_3];
	ld.param.u32 	%r9, [edgeDetectionLaplacianConv2D_param_4];
	cvta.to.global.u64 	%rd1, %rd7;
	cvta.to.global.u64 	%rd2, %rd8;
	mov.u32 	%r10, %ntid.y;
	mov.u32 	%r11, %ctaid.y;
	mov.u32 	%r12, %tid.y;
	mad.lo.s32 	%r1, %r11, %r10, %r12;
	mov.u32 	%r13, %ntid.x;
	mov.u32 	%r14, %ctaid.x;
	mov.u32 	%r15, %tid.x;
	mad.lo.s32 	%r2, %r14, %r13, %r15;
	setp.ge.s32 	%p1, %r1, %r9;
	setp.ge.s32 	%p2, %r2, %r8;
	or.pred  	%p3, %p2, %p1;
	@%p3 bra 	$L__BB3_20;

	add.s32 	%r3, %r1, -1;
	add.s32 	%r4, %r2, -1;
	or.b32  	%r16, %r4, %r3;
	setp.lt.s32 	%p4, %r16, 0;
	setp.gt.s32 	%p5, %r1, %r9;
	or.pred  	%p6, %p5, %p4;
	setp.gt.s32 	%p7, %r2, %r8;
	mad.lo.s32 	%r17, %r3, %r8, %r2;
	mul.wide.s32 	%rd9, %r17, 4;
	add.s64 	%rd3, %rd1, %rd9;
	mov.f32 	%f39, 0f00000000;
	or.pred  	%p8, %p7, %p6;
	@%p8 bra 	$L__BB3_3;

	ld.global.f32 	%f20, [%rd2];
	ld.global.f32 	%f21, [%rd3+-4];
	fma.rn.f32 	%f39, %f20, %f21, 0f00000000;

$L__BB3_3:
	or.b32  	%r18, %r2, %r3;
	setp.lt.s32 	%p9, %r18, 0;
	or.pred  	%p11, %p5, %p9;
	@%p11 bra 	$L__BB3_5;

	ld.global.f32 	%f22, [%rd3];
	ld.global.f32 	%f23, [%rd2+4];
	fma.rn.f32 	%f39, %f23, %f22, %f39;

$L__BB3_5:
	add.s32 	%r5, %r2, 1;
	or.b32  	%r19, %r5, %r3;
	setp.lt.s32 	%p12, %r19, 0;
	or.pred  	%p14, %p5, %p12;
	setp.ge.s32 	%p15, %r5, %r8;
	or.pred  	%p16, %p15, %p14;
	@%p16 bra 	$L__BB3_7;

	ld.global.f32 	%f24, [%rd3+4];
	ld.global.f32 	%f25, [%rd2+8];
	fma.rn.f32 	%f39, %f25, %f24, %f39;

$L__BB3_7:
	or.b32  	%r20, %r4, %r1;
	setp.lt.s32 	%p17, %r20, 0;
	mul.lo.s32 	%r6, %r1, %r8;
	add.s32 	%r21, %r2, %r6;
	mul.wide.s32 	%rd10, %r21, 4;
	add.s64 	%rd4, %rd1, %rd10;
	or.pred  	%p19, %p7, %p17;
	@%p19 bra 	$L__BB3_9;

	ld.global.f32 	%f26, [%rd4+-4];
	ld.global.f32 	%f27, [%rd2+12];
	fma.rn.f32 	%f39, %f27, %f26, %f39;

$L__BB3_9:
	or.b32  	%r22, %r2, %r1;
	setp.lt.s32 	%p20, %r22, 0;
	@%p20 bra 	$L__BB3_11;

	ld.global.f32 	%f28, [%rd4];
	ld.global.f32 	%f29, [%rd2+16];
	fma.rn.f32 	%f39, %f29, %f28, %f39;

$L__BB3_11:
	or.b32  	%r23, %r5, %r1;
	setp.lt.s32 	%p21, %r23, 0;
	or.pred  	%p23, %p15, %p21;
	@%p23 bra 	$L__BB3_13;

	ld.global.f32 	%f30, [%rd4+4];
	ld.global.f32 	%f31, [%rd2+20];
	fma.rn.f32 	%f39, %f31, %f30, %f39;

$L__BB3_13:
	add.s32 	%r7, %r1, 1;
	setp.ge.s32 	%p24, %r7, %r9;
	or.b32  	%r24, %r4, %r7;
	setp.lt.s32 	%p25, %r24, 0;
	or.pred  	%p26, %p24, %p25;
	add.s32 	%r25, %r6, %r8;
	add.s32 	%r26, %r2, %r25;
	mul.wide.s32 	%rd11, %r26, 4;
	add.s64 	%rd5, %rd1, %rd11;
	or.pred  	%p28, %p7, %p26;
	@%p28 bra 	$L__BB3_15;

	ld.global.f32 	%f32, [%rd5+-4];
	ld.global.f32 	%f33, [%rd2+24];
	fma.rn.f32 	%f39, %f33, %f32, %f39;

$L__BB3_15:
	or.b32  	%r27, %r2, %r7;
	setp.lt.s32 	%p29, %r27, 0;
	or.pred  	%p31, %p24, %p29;
	@%p31 bra 	$L__BB3_17;

	ld.global.f32 	%f34, [%rd5];
	ld.global.f32 	%f35, [%rd2+28];
	fma.rn.f32 	%f39, %f35, %f34, %f39;

$L__BB3_17:
	or.b32  	%r28, %r5, %r7;
	setp.lt.s32 	%p32, %r28, 0;
	or.pred  	%p34, %p24, %p32;
	or.pred  	%p36, %p15, %p34;
	@%p36 bra 	$L__BB3_19;

	ld.global.f32 	%f36, [%rd5+4];
	ld.global.f32 	%f37, [%rd2+32];
	fma.rn.f32 	%f39, %f37, %f36, %f39;

$L__BB3_19:
	add.s32 	%r29, %r6, %r2;
	cvta.to.global.u64 	%rd12, %rd6;
	mul.wide.s32 	%rd13, %r29, 4;
	add.s64 	%rd14, %rd12, %rd13;
	st.global.f32 	[%rd14], %f39;

$L__BB3_20:
	ret;

}
	// .globl	normalizeFloat
.visible .entry normalizeFloat(
	.param .u64 normalizeFloat_param_0,
	.param .u32 normalizeFloat_param_1,
	.param .u32 normalizeFloat_param_2
)
{
	.reg .pred 	%p<4>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<12>;
	.reg .b64 	%rd<5>;


	ld.param.u64 	%rd1, [normalizeFloat_param_0];
	ld.param.u32 	%r3, [normalizeFloat_param_1];
	ld.param.u32 	%r4, [normalizeFloat_param_2];
	mov.u32 	%r5, %ctaid.x;
	mov.u32 	%r6, %ntid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r1, %r5, %r6, %r7;
	mov.u32 	%r8, %ntid.y;
	mov.u32 	%r9, %ctaid.y;
	mov.u32 	%r10, %tid.y;
	mad.lo.s32 	%r2, %r9, %r8, %r10;
	setp.ge.s32 	%p1, %r1, %r3;
	setp.ge.s32 	%p2, %r2, %r4;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB4_2;

	cvta.to.global.u64 	%rd2, %rd1;
	mad.lo.s32 	%r11, %r2, %r3, %r1;
	mul.wide.s32 	%rd3, %r11, 4;
	add.s64 	%rd4, %rd2, %rd3;
	ld.global.f32 	%f1, [%rd4];
	div.rn.f32 	%f2, %f1, 0f437F0000;
	st.global.f32 	[%rd4], %f2;

$L__BB4_2:
	ret;

}

