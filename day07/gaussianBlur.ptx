//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-33281558
// Cuda compilation tools, release 12.3, V12.3.52
// Based on NVVM 7.0.1
//

.version 8.3
.target sm_86
.address_size 64

	// .globl	imageBlur

.visible .entry imageBlur(
	.param .u64 imageBlur_param_0,
	.param .u64 imageBlur_param_1,
	.param .u32 imageBlur_param_2,
	.param .u32 imageBlur_param_3,
	.param .u32 imageBlur_param_4,
	.param .u32 imageBlur_param_5
)
{
	.reg .pred 	%p<27>;
	.reg .b16 	%rs<10>;
	.reg .f32 	%f<158>;
	.reg .b32 	%r<67>;
	.reg .f64 	%fd<10>;
	.reg .b64 	%rd<13>;


	ld.param.u64 	%rd3, [imageBlur_param_0];
	ld.param.u64 	%rd2, [imageBlur_param_1];
	ld.param.u32 	%r19, [imageBlur_param_2];
	ld.param.u32 	%r20, [imageBlur_param_3];
	ld.param.u32 	%r21, [imageBlur_param_4];
	ld.param.u32 	%r22, [imageBlur_param_5];
	cvta.to.global.u64 	%rd1, %rd3;
	mov.u32 	%r23, %ntid.x;
	mov.u32 	%r24, %ctaid.x;
	mov.u32 	%r25, %tid.x;
	mad.lo.s32 	%r1, %r24, %r23, %r25;
	mov.u32 	%r26, %ntid.y;
	mov.u32 	%r27, %ctaid.y;
	mov.u32 	%r28, %tid.y;
	mad.lo.s32 	%r2, %r27, %r26, %r28;
	setp.ge.s32 	%p2, %r1, %r19;
	setp.ge.s32 	%p3, %r2, %r20;
	or.pred  	%p4, %p2, %p3;
	@%p4 bra 	$L__BB0_14;

	neg.s32 	%r3, %r21;
	setp.gt.s32 	%p5, %r3, %r21;
	mov.f32 	%f142, 0f00000000;
	mov.f32 	%f143, %f142;
	mov.f32 	%f144, %f142;
	mov.f32 	%f145, %f142;
	@%p5 bra 	$L__BB0_13;

	cvt.rn.f64.s32 	%fd2, %r22;
	add.f64 	%fd3, %fd2, %fd2;
	mul.f64 	%fd1, %fd3, %fd2;
	max.s32 	%r29, %r3, %r21;
	add.s32 	%r4, %r29, %r21;
	and.b32  	%r5, %r4, 1;
	mov.u32 	%r30, 1;
	sub.s32 	%r6, %r1, %r21;
	mul.lo.s32 	%r7, %r21, %r21;
	sub.s32 	%r8, %r30, %r21;
	mov.f32 	%f145, 0f00000000;
	mov.u32 	%r64, %r3;
	mov.f32 	%f144, %f145;
	mov.f32 	%f143, %f145;
	mov.f32 	%f142, %f145;

$L__BB0_3:
	add.s32 	%r31, %r64, %r2;
	setp.lt.s32 	%p6, %r31, %r20;
	setp.gt.s32 	%p7, %r31, -1;
	and.pred  	%p1, %p6, %p7;
	mul.lo.s32 	%r10, %r64, %r64;
	mul.lo.s32 	%r11, %r31, %r19;
	setp.ne.s32 	%p8, %r5, 0;
	mov.u32 	%r65, %r3;
	@%p8 bra 	$L__BB0_6;

	setp.lt.s32 	%p9, %r6, 0;
	setp.ge.s32 	%p10, %r6, %r19;
	not.pred 	%p11, %p1;
	or.pred  	%p12, %p11, %p10;
	or.pred  	%p13, %p9, %p12;
	mov.u32 	%r65, %r8;
	@%p13 bra 	$L__BB0_6;

	add.s32 	%r32, %r10, %r7;
	neg.s32 	%r33, %r32;
	cvt.rn.f64.s32 	%fd4, %r33;
	div.rn.f64 	%fd5, %fd4, %fd1;
	cvt.rn.f32.f64 	%f54, %fd5;
	mov.f32 	%f55, 0f3F000000;
	mov.f32 	%f56, 0f3BBB989D;
	fma.rn.f32 	%f57, %f54, %f56, %f55;
	cvt.sat.f32.f32 	%f58, %f57;
	mov.f32 	%f59, 0f4B400001;
	mov.f32 	%f60, 0f437C0000;
	fma.rm.f32 	%f61, %f58, %f60, %f59;
	add.f32 	%f62, %f61, 0fCB40007F;
	neg.f32 	%f63, %f62;
	mov.f32 	%f64, 0f3FB8AA3B;
	fma.rn.f32 	%f65, %f54, %f64, %f63;
	mov.f32 	%f66, 0f32A57060;
	fma.rn.f32 	%f67, %f54, %f66, %f65;
	mov.b32 	%r34, %f61;
	shl.b32 	%r35, %r34, 23;
	mov.b32 	%f68, %r35;
	ex2.approx.ftz.f32 	%f69, %f67;
	mul.f32 	%f70, %f69, %f68;
	add.s32 	%r36, %r6, %r11;
	mul.lo.s32 	%r37, %r36, 3;
	cvt.s64.s32 	%rd4, %r37;
	add.s64 	%rd5, %rd1, %rd4;
	ld.global.u8 	%rs1, [%rd5];
	cvt.rn.f32.u16 	%f71, %rs1;
	fma.rn.f32 	%f142, %f70, %f71, %f142;
	ld.global.u8 	%rs2, [%rd5+1];
	cvt.rn.f32.u16 	%f72, %rs2;
	fma.rn.f32 	%f143, %f70, %f72, %f143;
	ld.global.u8 	%rs3, [%rd5+2];
	cvt.rn.f32.u16 	%f73, %rs3;
	fma.rn.f32 	%f144, %f70, %f73, %f144;
	add.f32 	%f145, %f145, %f70;
	mov.u32 	%r65, %r8;

$L__BB0_6:
	setp.eq.s32 	%p14, %r4, 0;
	@%p14 bra 	$L__BB0_12;

$L__BB0_7:
	add.s32 	%r14, %r65, %r1;
	setp.ge.s32 	%p15, %r14, %r19;
	not.pred 	%p16, %p1;
	or.pred  	%p17, %p16, %p15;
	setp.lt.s32 	%p18, %r14, 0;
	or.pred  	%p19, %p18, %p17;
	@%p19 bra 	$L__BB0_9;

	mad.lo.s32 	%r38, %r65, %r65, %r10;
	neg.s32 	%r39, %r38;
	cvt.rn.f64.s32 	%fd6, %r39;
	div.rn.f64 	%fd7, %fd6, %fd1;
	cvt.rn.f32.f64 	%f74, %fd7;
	mov.f32 	%f75, 0f3F000000;
	mov.f32 	%f76, 0f3BBB989D;
	fma.rn.f32 	%f77, %f74, %f76, %f75;
	cvt.sat.f32.f32 	%f78, %f77;
	mov.f32 	%f79, 0f4B400001;
	mov.f32 	%f80, 0f437C0000;
	fma.rm.f32 	%f81, %f78, %f80, %f79;
	add.f32 	%f82, %f81, 0fCB40007F;
	neg.f32 	%f83, %f82;
	mov.f32 	%f84, 0f3FB8AA3B;
	fma.rn.f32 	%f85, %f74, %f84, %f83;
	mov.f32 	%f86, 0f32A57060;
	fma.rn.f32 	%f87, %f74, %f86, %f85;
	mov.b32 	%r40, %f81;
	shl.b32 	%r41, %r40, 23;
	mov.b32 	%f88, %r41;
	ex2.approx.ftz.f32 	%f89, %f87;
	mul.f32 	%f90, %f89, %f88;
	add.s32 	%r42, %r14, %r11;
	mul.lo.s32 	%r43, %r42, 3;
	cvt.s64.s32 	%rd6, %r43;
	add.s64 	%rd7, %rd1, %rd6;
	ld.global.u8 	%rs4, [%rd7];
	cvt.rn.f32.u16 	%f91, %rs4;
	fma.rn.f32 	%f142, %f90, %f91, %f142;
	ld.global.u8 	%rs5, [%rd7+1];
	cvt.rn.f32.u16 	%f92, %rs5;
	fma.rn.f32 	%f143, %f90, %f92, %f143;
	ld.global.u8 	%rs6, [%rd7+2];
	cvt.rn.f32.u16 	%f93, %rs6;
	fma.rn.f32 	%f144, %f90, %f93, %f144;
	add.f32 	%f145, %f145, %f90;

$L__BB0_9:
	add.s32 	%r15, %r65, 1;
	add.s32 	%r16, %r15, %r1;
	setp.ge.s32 	%p20, %r16, %r19;
	or.pred  	%p22, %p16, %p20;
	setp.lt.s32 	%p23, %r16, 0;
	or.pred  	%p24, %p23, %p22;
	@%p24 bra 	$L__BB0_11;

	mad.lo.s32 	%r44, %r15, %r15, %r10;
	neg.s32 	%r45, %r44;
	cvt.rn.f64.s32 	%fd8, %r45;
	div.rn.f64 	%fd9, %fd8, %fd1;
	cvt.rn.f32.f64 	%f94, %fd9;
	mov.f32 	%f95, 0f3F000000;
	mov.f32 	%f96, 0f3BBB989D;
	fma.rn.f32 	%f97, %f94, %f96, %f95;
	cvt.sat.f32.f32 	%f98, %f97;
	mov.f32 	%f99, 0f4B400001;
	mov.f32 	%f100, 0f437C0000;
	fma.rm.f32 	%f101, %f98, %f100, %f99;
	add.f32 	%f102, %f101, 0fCB40007F;
	neg.f32 	%f103, %f102;
	mov.f32 	%f104, 0f3FB8AA3B;
	fma.rn.f32 	%f105, %f94, %f104, %f103;
	mov.f32 	%f106, 0f32A57060;
	fma.rn.f32 	%f107, %f94, %f106, %f105;
	mov.b32 	%r46, %f101;
	shl.b32 	%r47, %r46, 23;
	mov.b32 	%f108, %r47;
	ex2.approx.ftz.f32 	%f109, %f107;
	mul.f32 	%f110, %f109, %f108;
	add.s32 	%r48, %r16, %r11;
	mul.lo.s32 	%r49, %r48, 3;
	cvt.s64.s32 	%rd8, %r49;
	add.s64 	%rd9, %rd1, %rd8;
	ld.global.u8 	%rs7, [%rd9];
	cvt.rn.f32.u16 	%f111, %rs7;
	fma.rn.f32 	%f142, %f110, %f111, %f142;
	ld.global.u8 	%rs8, [%rd9+1];
	cvt.rn.f32.u16 	%f112, %rs8;
	fma.rn.f32 	%f143, %f110, %f112, %f143;
	ld.global.u8 	%rs9, [%rd9+2];
	cvt.rn.f32.u16 	%f113, %rs9;
	fma.rn.f32 	%f144, %f110, %f113, %f144;
	add.f32 	%f145, %f145, %f110;

$L__BB0_11:
	add.s32 	%r65, %r65, 2;
	setp.lt.s32 	%p25, %r15, %r21;
	@%p25 bra 	$L__BB0_7;

$L__BB0_12:
	add.s32 	%r18, %r64, 1;
	setp.lt.s32 	%p26, %r64, %r21;
	mov.u32 	%r64, %r18;
	@%p26 bra 	$L__BB0_3;

$L__BB0_13:
	mad.lo.s32 	%r50, %r2, %r19, %r1;
	mul.lo.s32 	%r51, %r50, 3;
	div.rn.f32 	%f114, %f142, %f145;
	mov.b32 	%r52, %f114;
	and.b32  	%r53, %r52, -2147483648;
	or.b32  	%r54, %r53, 1056964608;
	mov.b32 	%f115, %r54;
	add.rz.f32 	%f116, %f114, %f115;
	cvt.rzi.f32.f32 	%f117, %f116;
	cvt.rzi.u32.f32 	%r55, %f117;
	cvt.s64.s32 	%rd10, %r51;
	cvta.to.global.u64 	%rd11, %rd2;
	add.s64 	%rd12, %rd11, %rd10;
	st.global.u8 	[%rd12], %r55;
	div.rn.f32 	%f118, %f143, %f145;
	mov.b32 	%r56, %f118;
	and.b32  	%r57, %r56, -2147483648;
	or.b32  	%r58, %r57, 1056964608;
	mov.b32 	%f119, %r58;
	add.rz.f32 	%f120, %f118, %f119;
	cvt.rzi.f32.f32 	%f121, %f120;
	cvt.rzi.u32.f32 	%r59, %f121;
	st.global.u8 	[%rd12+1], %r59;
	div.rn.f32 	%f122, %f144, %f145;
	mov.b32 	%r60, %f122;
	and.b32  	%r61, %r60, -2147483648;
	or.b32  	%r62, %r61, 1056964608;
	mov.b32 	%f123, %r62;
	add.rz.f32 	%f124, %f122, %f123;
	cvt.rzi.f32.f32 	%f125, %f124;
	cvt.rzi.u32.f32 	%r63, %f125;
	st.global.u8 	[%rd12+2], %r63;

$L__BB0_14:
	ret;

}

